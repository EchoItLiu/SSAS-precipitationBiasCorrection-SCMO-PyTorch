{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec data reading start........\n",
      "........ec class reading start........\n",
      "-------over-one-------\n",
      "min_channel: 54\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no matches found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5213d7f8001c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;31m#     ec_features, ec_features_path = PreECF(sys.argv[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;31m#     ec_features, ec_features_path = PreECF(timestamp_items[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mec_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mec_features_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreECF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;31m## generate fixed station list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5213d7f8001c>\u001b[0m in \u001b[0;36mPreECF\u001b[0;34m(preTimeStamp)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# ecf(2, 3_1, 4_2) ↔ ecpath(2, 3_1, 4_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mnc2EcFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc31EcFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc42EcFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_ec_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;31m#                 nc2EcFeatures, nc31EcFeatures = tsEC.ts_ec_selection()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5213d7f8001c>\u001b[0m in \u001b[0;36mts_ec_selection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mts_ec_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mnc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc3_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc4_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mec_Select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;31m#         nc2, nc3_1, pc1, pc2, pc3 = self.ec_Select()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5213d7f8001c>\u001b[0m in \u001b[0;36mec_Select\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprep_class_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mec_2_mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprecipitationFactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mprep_class_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mec_3_mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprecipitationFactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mprep_class_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mec_4_mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprecipitationFactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5213d7f8001c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprep_class_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mec_2_mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprecipitationFactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mprep_class_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mec_3_mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprecipitationFactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mprep_class_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mec_4_mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprecipitationFactors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpygrib.pyx\u001b[0m in \u001b[0;36mpygrib.open.select\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no matches found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import math\n",
    "import pygrib\n",
    "import pickle\n",
    "# import argparse\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import interpolate\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import math\n",
    "\n",
    "# \n",
    "rain_threshold = 0.1\n",
    "\n",
    "normalFactors = [\"Relative humidity\",\n",
    "              \"Vertical velocity\",\n",
    "              \"Temperature\",\n",
    "              \"V component of wind\",\n",
    "              \"U component of wind\",\n",
    "              \"Potential vorticity\",\n",
    "              \"Divergence\",\n",
    "              \"Geopotential Height\"\n",
    "              ]\n",
    "\n",
    "\n",
    "singleLevelFactors = [\"Total column water vapour\",\n",
    "                   \"Total column water\",\n",
    "                   \"Total cloud cover\"]\n",
    "\n",
    "\n",
    "#  ***  Convective precipitation ***\n",
    "precipitationFactors = [\"Large-scale precipitation\",\n",
    "                     \"Convective precipitation\",\n",
    "                     \"Total precipitation\"]\n",
    "\n",
    "# Level\n",
    "# levelsList = [500, 700, 850, 925]\n",
    "\n",
    "levelsList = [500, 700, 850]\n",
    "\n",
    "# Eastern Region\n",
    "east_locBound = (20, 40, 110, 124)\n",
    "\n",
    "# Value Range from Eastern Region (Enlarge 2°)\n",
    "# from top to bottom, from left to right\n",
    "sw_Bound_lat = np.arange(east_locBound[0] - 2,east_locBound[1] + 2 + 0.125, 0.125)[::-1]\n",
    "sw_Bound_lon = np.arange(east_locBound[2]- 2,east_locBound[3] + 2 + 0.125, 0.125)\n",
    "\n",
    "# interpolate range (refined and coarse)\n",
    "refined_lat = np.arange(0, east_locBound[1] - east_locBound[0] + 4 + 0.125, 0.125)\n",
    "refined_lon = np.arange(0, east_locBound[3] - east_locBound[2] + 4 + 0.125, 0.125)\n",
    "\n",
    "coarse_lat = np.arange(0, east_locBound[1] - east_locBound[0] + 4 + 0.25, 0.25)\n",
    "coarse_lon = np.arange(0, east_locBound[3] - east_locBound[2] + 4 + 0.25, 0.25)\n",
    "\n",
    "# setting\n",
    "    \n",
    "EC_path =\"/mnt/pami14/DATASET/METEOROLOGY/ECMWF2018\"\n",
    "\n",
    "GTmicaps_path = \"/mnt/pami14/DATASET/METEOROLOGY/micaps_16_18\"\n",
    "\n",
    "TS_path = \"/mnt/pami14/yqliu/biasCorrection/18ts_dataset_prep\"\n",
    "\n",
    "utility_path = \"/mnt/pami14/yqliu/biasCorrection/utility_dataset\"\n",
    "\n",
    "errors_path = \"/mnt/pami14/yqliu/biasCorrection/errors_text\"\n",
    "\n",
    "\n",
    "ts_length = 6\n",
    "\n",
    "slidingBar_stride = 1\n",
    "\n",
    "scope_slidingWindows =  0.125 * 1\n",
    "# h × w = 19 * 19\n",
    "scope_stationWindows = 18\n",
    "\n",
    "# argument for discarding non-rain\n",
    "discard_rainless_ratio = 0.8\n",
    "estimate_average_rainless_num = 600\n",
    "\n",
    "\n",
    "class TS_ec(object):\n",
    "    \n",
    "    def __init__(self, ecTuple):        \n",
    "        self.ecFilePath = ecTuple\n",
    "        \n",
    "    def ts_ec_selection(self):            \n",
    "        nc2, nc3_1, nc4_2, pc1, pc2, pc3, pc4 = self.ec_Select()\n",
    "#         nc2, nc3_1, pc1, pc2, pc3 = self.ec_Select()\n",
    "\n",
    "        nc_2_ec_features = self.ec_Data(nc2, 0, pc2, True)\n",
    "        nc3_1_ec_features = self.ec_Data(nc3_1, pc1, pc3, False)\n",
    "        nc4_2_ec_features = self.ec_Data(nc4_2, pc2, pc4, False)\n",
    "            \n",
    "        return nc_2_ec_features, nc3_1_ec_features, nc4_2_ec_features\n",
    "            \n",
    "                    \n",
    "    def ec_Select(self):\n",
    "        \n",
    "        ## open 5 EC files\n",
    "        # zero(0/12) \n",
    "        init_ec_mes = pygrib.open(self.ecFilePath[0])\n",
    "        # 3 / 15\n",
    "        ec_1_mes = pygrib.open(self.ecFilePath[1]) \n",
    "        # 6 / 18\n",
    "        ec_2_mes = pygrib.open(self.ecFilePath[2]) \n",
    "        # 9 / 21       \n",
    "        ec_3_mes = pygrib.open(self.ecFilePath[3])\n",
    "        # 12 / 00\n",
    "        ec_4_mes = pygrib.open(self.ecFilePath[4])\n",
    "        \n",
    "        ## select 5 EC Classes according to keywords of factors     \n",
    "        # normal Factors + singleLevelFactors\n",
    "        \n",
    "#         print ('........ec class reading start........')\n",
    "        before_time_1 = time.time()\n",
    "        nf_class_init = [init_ec_mes.select(name = keyFactor,level = keyLevel)[0] for keyFactor in normalFactors for keyLevel in levelsList] + [init_ec_mes.select(name = keyFactor)[0] for keyFactor in singleLevelFactors] \n",
    "        print ('-------over-one-------')\n",
    "        \n",
    "        nf_class_1 = [ec_1_mes.select(name = keyFactor,level = keyLevel)[0] for keyFactor in normalFactors for keyLevel in levelsList] + [ec_1_mes.select(name = keyFactor)[0] for keyFactor in singleLevelFactors]\n",
    "#         print ('-------over-two-------')\n",
    "        \n",
    "        nf_class_2 = [ec_2_mes.select(name = keyFactor,level = keyLevel)[0] for keyFactor in normalFactors for keyLevel in levelsList] +  [ec_2_mes.select(name = keyFactor)[0] for keyFactor in singleLevelFactors]\n",
    "        \n",
    "#         print ('-------over-three-------')\n",
    "\n",
    "        nf_class_3 = [ec_3_mes.select(name = keyFactor,level = keyLevel)[0] for keyFactor in normalFactors for keyLevel in levelsList] + [ec_3_mes.select(name = keyFactor)[0] for keyFactor in singleLevelFactors]\n",
    "        \n",
    "#         print ('-------over-four-------')       \n",
    "        nf_class_4 = [ec_4_mes.select(name = keyFactor,level = keyLevel)[0] for keyFactor in normalFactors for keyLevel in levelsList] + [ec_4_mes.select(name = keyFactor)[0] for keyFactor in singleLevelFactors]\n",
    "        after_time_1 = time.time()\n",
    "        print ('-------over-five-------')\n",
    "          ## Class Cost Time : 190s  \n",
    "#         print ('ec_class_cost_time:', after_time_1 - before_time_1)\n",
    "        \n",
    "        \n",
    "        # append normal Factors between 6h interval\n",
    "        nf_class_2 = nf_class_init  + nf_class_2\n",
    "        nf_class_3_1 = nf_class_3 + nf_class_1 \n",
    "        nf_class_4_2 = nf_class_4  + nf_class_2\n",
    "        \n",
    "        # assign normal factors between all combined factors \n",
    "#         min_channel = min(len(nf_class_2),len(nf_class_3_1),len(nf_class_4_2))\n",
    "        min_channel = min(len(nf_class_2),len(nf_class_3_1))\n",
    "        nf_class_2 = nf_class_2[:min_channel]\n",
    "        nf_class_3_1 = nf_class_3_1[:min_channel]\n",
    "        nf_class_4_2 = nf_class_4_2[:min_channel]\n",
    "        \n",
    "        print ('min_channel:', min_channel)\n",
    "        \n",
    "        # precipitation\n",
    "        prep_class_1 = [ec_1_mes.select(name = keyFactor)[0] for keyFactor in precipitationFactors]\n",
    "        prep_class_2 = [ec_2_mes.select(name = keyFactor)[0] for keyFactor in precipitationFactors]\n",
    "        prep_class_3 = [ec_3_mes.select(name = keyFactor)[0] for keyFactor in precipitationFactors]\n",
    "        prep_class_4 = [ec_4_mes.select(name = keyFactor)[0] for keyFactor in precipitationFactors]\n",
    "               \n",
    "        ## Normal Factors data according to Eastern Region\n",
    "        return nf_class_2, nf_class_3_1, nf_class_4_2, prep_class_1, prep_class_2, prep_class_3, prep_class_4  \n",
    "        \n",
    "    \n",
    "    def ec_Data(self, nc_interval, before_pc, after_pc, flag_0):\n",
    "        ec_features  = []\n",
    "#         before_time_2= time.time()\n",
    "#         print ('........ec data reading start........')\n",
    "        for nc_grib in nc_interval:\n",
    "            grib_data = nc_grib.data(lat1 = east_locBound[0] - 2, lat2 = east_locBound[1] + 2, lon1 = east_locBound[2] - 2, lon2 = east_locBound[3] + 2)[0]\n",
    "          \n",
    "            if grib_data.shape[0]< len(refined_lat):\n",
    "                \n",
    "                grib_data = interpolate.interp2d(coarse_lon, coarse_lat, grib_data, kind='linear')( refined_lon, refined_lat) \n",
    "        \n",
    "            ec_features.append(grib_data)\n",
    "        \n",
    "        if flag_0: \n",
    "            before_prep_date = before_pc\n",
    "            \n",
    "        else:               \n",
    "            before_prep_date = [bf_pc.data(lat1 = east_locBound[0] - 2, lat2 = east_locBound[1] + 2, lon1 = east_locBound[2] - 2, lon2 = east_locBound[3] + 2)[0] * 1000 for bf_pc in before_pc]\n",
    "                   \n",
    "        after_prep_date = [af_pc.data(lat1 = east_locBound[0] - 2, lat2 = east_locBound[1] + 2, lon1 = east_locBound[2] - 2, lon2 = east_locBound[3] + 2)[0] * 1000 for af_pc in after_pc]\n",
    "        \n",
    "        \n",
    "        if flag_0:         \n",
    "            interval_prep_date = after_prep_date\n",
    "            \n",
    "        else:\n",
    "            interval_prep_date = [inv for inv in (map(lambda x: x[1] - x[0], zip(before_prep_date, after_prep_date)))]\n",
    "            \n",
    "        ec_features += interval_prep_date\n",
    "               \n",
    "        # list → numpy\n",
    "        ec_features = np.stack(ec_features)\n",
    "        after_time_2= time.time()\n",
    "        ## Data Average Cost Time : 16s         \n",
    "#         print ('ec_data_cost_time:', after_time_2 - before_time_2)\n",
    "        return ec_features\n",
    "    \n",
    "    \n",
    "def PreECF(preTimeStamp):\n",
    "    \n",
    "    # init    \n",
    "    ecPath = EC_path\n",
    "    # 20180x\n",
    "    preTimeStamp_A = list(preTimeStamp)\n",
    "    \n",
    "    # 2018-0x\n",
    "    preTimeStamp_A.insert(4, '-')    \n",
    "    start_time = ''.join(preTimeStamp_A)\n",
    "        \n",
    "    ec_features_l = []\n",
    "    ec_features_path_l = []\n",
    "    \n",
    "    if isinstance(start_time, str):\n",
    "        \n",
    "        start_time_path = os.path.join(ecPath,start_time)\n",
    "        month_days_l = os.listdir(start_time_path)\n",
    "        month_days_l.sort()\n",
    "        month_days_l = month_days_l[0:3]\n",
    "    \n",
    "        for day in month_days_l:\n",
    "            \n",
    "            day_path  = os.path.join(ecPath, start_time, day)        \n",
    "            day_ecs = os.listdir(day_path)            \n",
    "            day_ecs.sort()\n",
    "            \n",
    "            l = [0,5]\n",
    "            \n",
    "            for ii in l:\n",
    "                # init(——)(00/12)\n",
    "                init_ec_path = os.path.join(ecPath, start_time, day, day_ecs[ii])\n",
    "                # 3 / 15\n",
    "                ec_1_path = os.path.join(ecPath, start_time, day, day_ecs[1 + ii])\n",
    "                print ('EC_PATH_1:', ec_1_path)                \n",
    "                # 6 / 18\n",
    "                ec_2_path = os.path.join(ecPath, start_time, day, day_ecs[2 + ii])\n",
    "                # 9 / 21\n",
    "                ec_3_path = os.path.join(ecPath, start_time, day, day_ecs[3 + ii])\n",
    "                # 12 / 00        \n",
    "                ec_4_path = os.path.join(ecPath, start_time, day, day_ecs[4 + ii])\n",
    "                print ('EC_PATH_4:', ec_1_path)                \n",
    "                \n",
    "                tsEC = TS_ec((init_ec_path, ec_1_path, ec_2_path, ec_3_path, ec_4_path))       \n",
    "#                 tsEC = TS_ec((init_ec_path, ec_1_path, ec_2_path, ec_3_path))\n",
    "        \n",
    "                # ecf(2, 3_1, 4_2) ↔ ecpath(2, 3_1, 4_2)\n",
    "                nc2EcFeatures, nc31EcFeatures, nc42EcFeatures = tsEC.ts_ec_selection()\n",
    "#                 nc2EcFeatures, nc31EcFeatures = tsEC.ts_ec_selection()\n",
    "\n",
    "                        \n",
    "            ec_features_l.append(nc2EcFeatures)\n",
    "            ec_features_l.append(nc31EcFeatures)\n",
    "            ec_features_l.append(nc42EcFeatures)\n",
    "           \n",
    "        \n",
    "            # 不需要0时刻的~\n",
    "            ec_features_path_l.append(ec_2_path)\n",
    "            ec_features_path_l.append(ec_3_path)\n",
    "            ec_features_path_l.append(ec_4_path)\n",
    "                        \n",
    "    # list → numpy [N*C*H*W]\n",
    "    ec_features = np.stack(ec_features_l)\n",
    "       \n",
    "    # list → numpy [N]\n",
    "    ec_features_path = np.array(ec_features_path_l)\n",
    "    \n",
    "    return ec_features, ec_features_path \n",
    "        \n",
    "    \n",
    "def fixStation():\n",
    "\n",
    "    micapsPath = GTmicaps_path\n",
    "    ## select fixed 3 micaps file\n",
    "    ## fixed_station_number: 1188  17080608.000  17070814.000  16081020.000\"\"\"\n",
    "    candi_mi_path1 = os.path.join(micapsPath, \"2017\", \"08\", \"surface\", \"r6-p\", \"17080608.000\")\n",
    "    candi_mi_path2 = os.path.join(micapsPath, \"2017\", \"07\", \"surface\", \"r6-p\", \"17070814.000\")\n",
    "    candi_mi_path3 = os.path.join(micapsPath, \"2016\", \"08\", \"surface\", \"r6-p\", \"16081020.000\")\n",
    "\n",
    "    candi_paths_l = [candi_mi_path1, candi_mi_path2, candi_mi_path3]\n",
    "    # init \n",
    "    index_l = []\n",
    "    lats_d = {}\n",
    "    lons_d = {}\n",
    "\n",
    "    for cPath in candi_paths_l:\n",
    "\n",
    "        if not os.path.exists(cPath):\n",
    "            print(\"candidate micaps not exists!\")\n",
    "\n",
    "        with open(cPath, encoding=\"GBK\") as f:  \n",
    "            cPath_data = f.readlines()\n",
    "            key_data = cPath_data[14:]\n",
    "\n",
    "        for oneLine in key_data:\n",
    "            oneLabel = oneLine.split()\n",
    "            index, lon, lat, _, _ = map(float, oneLabel) \n",
    "\n",
    "            # select strictly\n",
    "            if (lat < east_locBound[0]) or (lat > east_locBound[1]):\n",
    "                continue\n",
    "            elif (lon < east_locBound[2]) or (lon > east_locBound[3]):\n",
    "                continue\n",
    "            else:\n",
    "                index_l.append(index)                       \n",
    "                lats_d[index] = lat        \n",
    "                lons_d[index] = lon\n",
    "\n",
    "    # remove redundancy and fixed indice      \n",
    "    index_fixed = np.unique(np.array(index_l))     \n",
    "    # get lat/lon pairs [(index, lat, lon),...]\n",
    "    lats_lons_item = [(fIdx, lats_d[fIdx], lons_d[fIdx]) for fIdx in index_fixed]\n",
    "    return lats_lons_item\n",
    "    \n",
    "           \n",
    "class pre_ts_ecData(object):\n",
    "    def __init__(self, ecFeatures, ecFeaturePaths, latLonEntries, monthTimeStamp):\n",
    "        self.savePath = TS_path\n",
    "        self.micapsPath = GTmicaps_path\n",
    "        self.errorPath = errors_path\n",
    "        self.latlons_item = latLonEntries\n",
    "        self.ec_Features = ecFeatures\n",
    "        self.ec_FeaturePaths = ecFeaturePaths\n",
    "        self.monthTimeStamp = monthTimeStamp \n",
    "        self.scopeSW = scope_slidingWindows\n",
    "        self.scopeGW = scope_stationWindows\n",
    "        self.tsLen = ts_length\n",
    "        self.slidB = slidingBar_stride\n",
    "        self.ec_features_ts_l = []\n",
    "        self.ec_features_path_ts = []\n",
    "        self.stride = round(discard_rainless_ratio / (estimate_average_rainless_num * discard_rainless_ratio), 5)        \n",
    "        self.sliceWindows4LatLon()\n",
    "        self.slidingTSec()\n",
    "        self.gainGT4ecPath()\n",
    "  \n",
    "        \n",
    "    \n",
    "    def sliceWindows4LatLon(self):\n",
    "        \n",
    "        ec_features_stations_l = []\n",
    "        update_lats_lons_item = []\n",
    "        update_indice = []\n",
    "        # station windows range → h × w\n",
    "        self.gw_range = math.floor(self.scopeGW / 2)\n",
    "        \n",
    "        for k in tqdm.tqdm(\n",
    "                range(len(self.latlons_item)), total=len(self.latlons_item),\n",
    "                desc='Load StationWindows', ncols=80,\n",
    "                leave = True):\n",
    "            flag = False\n",
    "            for i, lat in enumerate(sw_Bound_lat):\n",
    "                if flag == True:\n",
    "                    break\n",
    "                for j, lon in enumerate(sw_Bound_lon):\n",
    "                    # sliding window scope\n",
    "                    \n",
    "                    lat_range = (lat - self.scopeSW, lat)\n",
    "                    lon_range = (lon, lon + self.scopeSW)  \n",
    "                    \n",
    "                    # search and matching\n",
    "                    if self.latlons_item[k][1]<=lat_range[1] and self.latlons_item[k][1]>=lat_range[0] \\\n",
    "                    and self.latlons_item[k][2] <= lon_range[1] and self.latlons_item[k][2]>= lon_range[0]:\n",
    "                    # slice station windows - from bottom to top ,and from left to right \n",
    "                    # windows shape - [self.scopeGW * self.scopeGW]\n",
    "                        ec_features_stations_l.append(self.ec_Features[:,:,(i - self.gw_range):(i + self.gw_range + 1), (j - self.gw_range):(j + self.gw_range + 1)])\n",
    "                    # save existing station info.\n",
    "                        update_indice.append(self.latlons_item[k][0])\n",
    "                        \n",
    "                        flag = True\n",
    "                        break\n",
    "                        \n",
    "                                  \n",
    "        # list → numpy n * N * C * h * w (float32) \n",
    "        self.ec_features_stations = np.stack(ec_features_stations_l).astype(np.float32)\n",
    "        \n",
    "        print ('EC_FEATURES_STATIONS:', self.ec_features_stations.shape)\n",
    "        \n",
    "        # n \n",
    "        self.update1_indice  = update_indice\n",
    "        \n",
    "        if len(self.update1_indice) < 1188:\n",
    "            errorStr = 'Update Stations is Inconsistent!\\n'\n",
    "            with open(os.path.join(self.errorPath, \"error_log.txt\"), \"a+\", encoding='utf-8') as f:\n",
    "                f.write(errorStr)    \n",
    "\n",
    "                \n",
    "        ### saving Xarray to one file\n",
    "        # output: ec_features_s --  n * N * C * h * w\n",
    "        # update_indice  n\n",
    "        # ecFeaturePaths  N\n",
    "        # C random for aligning\n",
    "        # h random for aligning\n",
    "        # w random for aligning\n",
    "        \n",
    "                              \n",
    "              \n",
    "    def slidingTSec(self):\n",
    "\n",
    "        b_idx = 0\n",
    "        e_idx = self.tsLen - 1\n",
    "        self.ec_features_ts = []\n",
    "        self.ec_features_path_ts = []\n",
    "        l_count = 0\n",
    "        # N * n * C * h * w\n",
    "        ec_features_s = np.transpose(self.ec_features_stations,(1,0,2,3,4))\n",
    "        \n",
    "        while (e_idx) <= (len(ec_features_s)-1):\n",
    "            if l_count == 0 and e_idx > (len(ec_features_s)-1):\n",
    "                print (\"ec length is smaller than time-series sequence. please reset argument!\")\n",
    "                break\n",
    "               \n",
    "            self.ec_features_ts.append(ec_features_s[b_idx:(b_idx + self.tsLen)])\n",
    "            self.ec_features_path_ts.append(self.ec_FeaturePaths[b_idx + self.tsLen - 1])\n",
    "\n",
    "            b_idx = b_idx + self.slidB\n",
    "            e_idx = e_idx + self.slidB\n",
    "            l_count = l_count + 1\n",
    "            \n",
    "        # L * D * n * C * h * w  /  L \n",
    "        # one sample: C * D * h * w FEATURES - 1 GT\n",
    "        # one sample: C * D * h * w FEATURES - (D-τ) GT must unify stationID\n",
    "        print ('EC_FEATURES_ALL_SEQUENCE:', len(self.ec_features_ts)) \n",
    "        \n",
    "           \n",
    "    def gainGT4ecPath(self):\n",
    "        \n",
    "        # month path\n",
    "        current_pkl_list = os.listdir(self.savePath)\n",
    "        \n",
    "        # file series\n",
    "        if current_pkl_list==[]:\n",
    "            seriesNo = 0\n",
    "\n",
    "        if current_pkl_list!=[]:\n",
    "            seriesNo = 0\n",
    "\n",
    "            for PrepklName in current_pkl_list:\n",
    "                \n",
    "                PrepklTime = datetime.datetime.strptime(PrepklName[-6:], \"%Y%m\")\n",
    "                PostpklTime = datetime.datetime.strptime(self.monthTimeStamp[:-2], \"%Y%m\")\n",
    "\n",
    "                if (PostpklTime - PrepklTime)>=datetime.timedelta(days=31) or \\\n",
    "                  (PostpklTime - PrepklTime)>=datetime.timedelta(days=30):\n",
    "                    seriesNo = seriesNo + 1 \n",
    "                                       \n",
    "        month_path = \"{}-seq\".format(seriesNo) + self.monthTimeStamp[:-2]\n",
    "                        \n",
    "        \n",
    "        \n",
    "        count_total_samples = 0\n",
    "        count_rain_samples = 0\n",
    "        count_rainless_samples = 0\n",
    "        \n",
    "        for lth, fileName in tqdm.tqdm(\n",
    "                enumerate(self.ec_features_path_ts), total=len(self.ec_features_path_ts),\n",
    "                desc='Load One Data', ncols=80,\n",
    "                leave = True):\n",
    "\n",
    "            ## init\n",
    "            # D * n * C * h * w →  n * C * D * h * w \n",
    "            ec_features_ts_lth = self.ec_features_ts[lth].transpose(1,0,2,3,4).transpose(0,2,1,3,4)\n",
    "            xar_dic = {}\n",
    "            update_ec_features_ts_l = []\n",
    "            mi_dic_gt = {}\n",
    "            mi_dic_latlons = {}\n",
    "            indice = []\n",
    "            timeLevel_stationIndice = []\n",
    "                      \n",
    "            \n",
    "            # micaps file\n",
    "            # /mnt/pami14/DATASET/METEOROLOGY/ECMWF2018/2018-01/0101/C1D01010000010103001\n",
    "            fileNameSplit = fileName.split(\"/\")\n",
    "#             print ('FileNameSPLIT:', fileNameSplit)\n",
    "            fileNameStr = fileNameSplit[-1]\n",
    "            # 010103\n",
    "            oldMdhStr = fileNameStr[-9:-3]\n",
    "            # 2018-01\n",
    "            oldYearStr = fileNameSplit[-3][0:4]\n",
    "#             print ('YEAR:', oldYearStr)\n",
    "            # 201801\n",
    "#             oldYearStr = oldYearStr.replace('-', '')\n",
    "            labelDateStr = oldYearStr + oldMdhStr\n",
    "            \n",
    "            print ('YMDH:', labelDateStr)\n",
    "            # convert BJ time\n",
    "            labelDate = datetime.datetime.strptime(labelDateStr, \"%Y%m%d%H\") + datetime.timedelta(hours=8)\n",
    "            yearStr = labelDate.strftime(\"%Y\")\n",
    "            monthStr = labelDate.strftime(\"%m\")\n",
    "\n",
    "            labelDirName = os.path.join(self.micapsPath, yearStr, monthStr, \"surface\", \"r6-p\")\n",
    "            labelFileName = datetime.datetime.strftime(labelDate, \"%Y%m%d%H\")[2:] + \".000\"\n",
    "            labelFileFullName = os.path.join(labelDirName, labelFileName)\n",
    "\n",
    "            if not os.path.exists(labelFileFullName):\n",
    "                print(\"closed micaps File is not exist!\")\n",
    "                continue\n",
    "                \n",
    "            with open(labelFileFullName, encoding=\"GBK\") as f:\n",
    "\n",
    "                mData = f.readlines()\n",
    "                micaps_data = mData[14:]\n",
    "\n",
    "            for oneLine in micaps_data:\n",
    "                oneLabel = oneLine.split()\n",
    "                index, lon, lat, _, value = map(float, oneLabel)\n",
    "                mi_dic_gt[index] = value\n",
    "                mi_dic_latlons[index] = (lat,lon)\n",
    "                indice.append(index)\n",
    "                \n",
    "            \n",
    "            for v, up_index in enumerate(self.update1_indice):   \n",
    "                # alignment: no EC (ignore GT) or no micapsGT(ignore EC) \n",
    "                if up_index in indice:\n",
    "\n",
    "                    lat_up, lon_up = mi_dic_latlons[up_index]\n",
    "                    gt_prep_value = mi_dic_gt[up_index]\n",
    "                    \n",
    "                    count_total_samples = count_total_samples + 1\n",
    "                    \n",
    "                    if gt_prep_value < rain_threshold:\n",
    "                        continue \n",
    "\n",
    "                    if gt_prep_value > rain_threshold:  \n",
    "                        count_rain_samples = count_rain_samples  + 1\n",
    "                        \n",
    "                    if gt_prep_value<0.05:\n",
    "                        count_rainless_samples = count_rainless_samples + 1\n",
    "                    \n",
    "                    count_total_samples = count_total_samples + 1\n",
    "                    \n",
    "                                       \n",
    "                    # slice lat/lon range\n",
    "                    lat_upper_bound = lat_up + self.gw_range * 0.125\n",
    "                    lat_lower_bound = lat_up - self.gw_range * 0.125\n",
    "                    lon_left_bound = lon_up - self.gw_range * 0.125\n",
    "                    lon_right_bound = lon_up + self.gw_range* 0.125 \n",
    "                    \n",
    "                                                           \n",
    "                    # from top to bottom , from left to right\n",
    "                    lat_range = list(np.arange(lat_lower_bound, lat_upper_bound + 0.125, 0.125)[:19])\n",
    "                    lat_range = np.array([round(i,2) for i in lat_range]).astype(np.float32)\n",
    "                    lon_range = list(np.arange(lon_left_bound, lon_right_bound + 0.125, 0.125)[:19])\n",
    "                    lon_range = np.array([round(i,2) for i in lon_range]).astype(np.float32)\n",
    "                    channel_num_l = np.arange(0, ec_features_ts_lth[v].shape[0], 1)\n",
    "                    dynamic_num_l = np.arange(0, ec_features_ts_lth[v].shape[1], 1)\n",
    "\n",
    "                    # create xarray -  C * D * h * w (float 32)               \n",
    "                    xar = xr.DataArray(ec_features_ts_lth[v].astype(np.float32), coords=[channel_num_l, dynamic_num_l, lat_range, lon_range], dims=['key_channel','seq_length','lat_range','lon_range'])\n",
    "                    xar.attrs['prep_gt'] =  mi_dic_gt[up_index]\n",
    "                    xar.attrs['fix_stationIndice'] = np.array(self.update1_indice).astype(np.float32)\n",
    "                    timeLevel_stationIndice.append(up_index)\n",
    "                                       \n",
    "                    xar_dic[up_index] = xar\n",
    "                    \n",
    "                    ## count\n",
    "       \n",
    "            ## save according to time level            \n",
    "            # (n - τ) * C * D * h * w saving xarray, τ is uncertainty\n",
    "            \n",
    "            # file path\n",
    "            pklFilePath = os.path.join(self.savePath, month_path)\n",
    "            if not os.path.exists(pklFilePath):\n",
    "                os.mkdir(pklFilePath)\n",
    "                \n",
    "            pkl_name = os.path.join(pklFilePath, fileName.split(\"/\")[-3]+fileName.split(\"/\")[-1][-9:-3]+\".pkl\")\n",
    "\n",
    "            with open(pkl_name,\"wb\") as f:\n",
    "                pickle.dump(xar_dic, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                \n",
    "                                                                                         \n",
    "        print ('TOTALsamples:', count_total_samples)\n",
    "        print ('RAINsamples:', count_rain_samples)\n",
    "        print ('RAINLESSsamples:', count_rainless_samples)\n",
    "        \n",
    "                                                    \n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    \n",
    "    timestamp_items = ['201801','201802','201803','201804','201805','201806','201807','201808','201809','201810']    \n",
    "    \n",
    "    for item in timestamp_items:\n",
    "#     ec_features, ec_features_path = PreECF(sys.argv[1])\n",
    "#     ec_features, ec_features_path = PreECF(timestamp_items[0])\n",
    "        ec_features, ec_features_path = PreECF(item) \n",
    "    \n",
    "    ## generate fixed station list\n",
    "        fixstation_path = os.path.join(utility_path, \"stationItem.npy\")\n",
    "\n",
    "        if not os.path.exists(fixstation_path): \n",
    "            # type: list\n",
    "            latLonItem = fixStation()\n",
    "            np.save(fixstation_path, latLonItem)\n",
    "        else:\n",
    "            # type: numpy ndarray\n",
    "            latLonItem = np.load(fixstation_path)\n",
    "\n",
    "    #     pre_ts_ecData(ec_features, ec_features_path, latLonItem, sys.argv[1])\n",
    "#         pre_ts_ecData(ec_features, ec_features_path, latLonItem, timestamp_items[0])\n",
    "        pre_ts_ecData(ec_features, ec_features_path, latLonItem, item)\n",
    "\n",
    "        afterOpentime = time.time()\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
