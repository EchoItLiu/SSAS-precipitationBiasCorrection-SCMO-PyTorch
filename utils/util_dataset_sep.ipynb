{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModalsFeatureNormS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load feature and cache the mean and std of features...\n",
      "3---\n",
      "4---\n",
      "5---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# base path\n",
    "utilityPath = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/util_dataset\"\n",
    "cropRoot = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/1617_modalsEC\"   \n",
    "meanFilePath = os.path.join(utilityPath, \"mean_s_modal.npy\")\n",
    "stdFilePath = os.path.join(utilityPath, \"std_s_modal.npy\")\n",
    "\n",
    "hw = 29\n",
    "channelNums = 57\n",
    "\n",
    "\n",
    "\n",
    "# flatten path\n",
    "if not os.path.exists(meanFilePath) or not os.path.exists(stdFilePath):\n",
    "    print(\"Start to load feature and cache the mean and std of features...\")\n",
    "    cropFileList = [os.path.join(cropRoot, fileName, pklName) for fileName in\n",
    "        os.listdir(cropRoot) for pklName in os.listdir(os.path.join(cropRoot, fileName))]\n",
    "\n",
    "    cacheList = []\n",
    "\n",
    "    for fileName in cropFileList:\n",
    "\n",
    "        # oneCropDataDict → DataArray \n",
    "        with open(fileName, 'rb') as f:\n",
    "            oneCropDataDict = pickle.load(f)\n",
    "\n",
    "        # shape_oneCrop_ → station_num × f_keys(C) × H × W\n",
    "        for cropData in oneCropDataDict.values():\n",
    "            # shape_cropData →  f_keys(C) × HW\n",
    "            features = cropData.values[:,-1,:,:].reshape(channelNums, hw * hw)\n",
    "            # save all (f_keys(C) × HW)s to list\n",
    "            cacheList.append(features)\n",
    "            \n",
    "            \n",
    "    # concat all pixels for all Cs(channels) C* nHW \n",
    "    concatenateFeatures = np.concatenate(cacheList, axis = 1)\n",
    "    print (\"3---\")   \n",
    "    # cal mean for all Cs(channels) and save mean arrays in *.npy  \n",
    "    np.save(meanFilePath, concatenateFeatures.mean(axis = 1))\n",
    "    print (\"4---\")\n",
    "    # cal standard for all Cs(channels) and save standard arrays in *.npy \n",
    "    np.save(stdFilePath, concatenateFeatures.std(axis = 1))\n",
    "    print (\"5---\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModalsFeatureNormST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load feature and cache the mean and std of features...\n",
      "3---\n",
      "4---\n",
      "5---\n"
     ]
    }
   ],
   "source": [
    "# base path\n",
    "utilityPath = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/util_dataset\"\n",
    "cropRoot = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/1617_modalsEC\"   \n",
    "meanFilePath = os.path.join(utilityPath, \"mean_st_modal.npy\")\n",
    "stdFilePath = os.path.join(utilityPath, \"std_st_modal.npy\")\n",
    "\n",
    "hw = 29\n",
    "channelNums = 57\n",
    "\n",
    "tsLength = 6\n",
    "\n",
    "z_total_features_l = []\n",
    "\n",
    "\n",
    "# flatten path\n",
    "if not os.path.exists(meanFilePath) or not os.path.exists(stdFilePath):\n",
    "    print(\"Start to load feature and cache the mean and std of features...\")\n",
    "    cropFileList = [os.path.join(cropRoot, fileName, pklName) for fileName in\n",
    "        os.listdir(cropRoot) for pklName in os.listdir(os.path.join(cropRoot, fileName))]\n",
    "\n",
    "\n",
    "    for i, zFilePath in enumerate(cropFileList):           \n",
    "        with open(zFilePath, 'rb') as f:\n",
    "            xarDicData = pickle.load(f)\n",
    "#             print (\"0---\")\n",
    "            \n",
    "        for xar in xarDicData.values():\n",
    "            # C * D * h * w\n",
    "            xar_features = xar.values\n",
    "            # C * D * h * w → C * D * hw             \n",
    "            xar_nN_hw = xar_features.reshape(channelNums, tsLength, hw*hw)\n",
    "#             print (\"1---\")\n",
    "            # C * D * hw  → C * Dhw  \n",
    "            xar_nN_D = xar_nN_hw.reshape(channelNums, -1)\n",
    "#             print (\"2---\")\n",
    "            z_total_features_l.append(xar_nN_D)\n",
    "\n",
    "\n",
    "    # l * C * Dhw → C * lDhw\n",
    "    z_C = np.concatenate(z_total_features_l, 1) \n",
    "    print (\"3---\")\n",
    "    # mean + std\n",
    "    np.save(meanFilePath, z_C.mean(axis = 1))\n",
    "    print (\"4---\")\n",
    "    np.save(stdFilePath, z_C.std(axis = 1))\n",
    "    print (\"5---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load feature and cache the mean and std of features...\n",
      "3---\n",
      "4---\n",
      "5---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# base path\n",
    "utilityPath = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/util_dataset\"\n",
    "# cropRoot = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/1617_modalsEC\"\n",
    "cropRoot = \"/mnt/pami23/yqliu/ycluo/cropdata_ts\"   \n",
    "\n",
    "meanFilePath = os.path.join(utilityPath, \"mean_st_modal_37.npy\")\n",
    "stdFilePath = os.path.join(utilityPath, \"std_st_modal_37.npy\")\n",
    "\n",
    "hw = 19\n",
    "channelNums = 37\n",
    "\n",
    "tsLength = 6\n",
    "\n",
    "z_total_features_l = []\n",
    "\n",
    "fileName = '1-seq201609'\n",
    "\n",
    "# flatten path\n",
    "if not os.path.exists(meanFilePath) or not os.path.exists(stdFilePath):\n",
    "    print(\"Start to load feature and cache the mean and std of features...\")\n",
    "#     cropFileList = [os.path.join(cropRoot, fileName, pklName) for fileName in\n",
    "#         os.listdir(cropRoot) for pklName in os.listdir(os.path.join(cropRoot, fileName))]\n",
    "\n",
    "    cropFileList = [os.path.join(cropRoot, fileName, pklName) for pklName in os.listdir(os.path.join(cropRoot, fileName))]    \n",
    "\n",
    "    for i, zFilePath in enumerate(cropFileList):           \n",
    "        with open(zFilePath, 'rb') as f:\n",
    "            xarDicData = pickle.load(f)\n",
    "#             print (\"0---\")\n",
    "            \n",
    "        for xar in xarDicData.values():\n",
    "            # C * D * h * w\n",
    "            xar_features = np.concatenate((xar.values[0:35], xar.values[55:]),0)\n",
    "            # C * D * h * w → C * D * hw             \n",
    "            xar_nN_hw = xar_features.reshape(channelNums, tsLength, hw*hw)\n",
    "#             print (\"1---\")\n",
    "            # C * D * hw  → C * Dhw  \n",
    "            xar_nN_D = xar_nN_hw.reshape(channelNums, -1)\n",
    "#             print (\"2---\")\n",
    "            z_total_features_l.append(xar_nN_D)\n",
    "\n",
    "\n",
    "    # l * C * Dhw → C * lDhw\n",
    "    z_C = np.concatenate(z_total_features_l, 1) \n",
    "    print (\"3---\")\n",
    "    # mean + std\n",
    "    np.save(meanFilePath, z_C.mean(axis = 1))\n",
    "    print (\"4---\")\n",
    "    np.save(stdFilePath, z_C.std(axis = 1))\n",
    "    print (\"5---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FD TS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load feature and cache the mean and std of features...\n",
      "3---\n",
      "4---\n",
      "5---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# base path\n",
    "utilityPath = \"/mnt/pami23/yqliu/cropdata_modal_util\"\n",
    "# cropRoot = \"/mnt/pami14/yqliu/EC-BiasCorrecting/SHO/1617_modalsEC\"\n",
    "cropRoot = \"/mnt/pami23/yqliu/cropdata_modal\"   \n",
    "#\n",
    "meanFilePath = os.path.join(utilityPath, \"mean_fd_modal_57.npy\")\n",
    "stdFilePath = os.path.join(utilityPath, \"std_fd_modal_57.npy\")\n",
    "\n",
    "hw = 17\n",
    "channelNums = 37\n",
    "\n",
    "tsLength = 6\n",
    "\n",
    "z_total_features_l = []\n",
    "\n",
    "# fileName = '1-seq201609'\n",
    "\n",
    "# flatten path\n",
    "if not os.path.exists(meanFilePath) or not os.path.exists(stdFilePath):\n",
    "    print(\"Start to load feature and cache the mean and std of features...\")\n",
    "#     cropFileList = [os.path.join(cropRoot, fileName, pklName) for fileName in\n",
    "#         os.listdir(cropRoot) for pklName in os.listdir(os.path.join(cropRoot, fileName))]\n",
    "\n",
    "    cropFileList = [os.path.join(cropRoot, fileName, pklName) for fileName in\n",
    "        os.listdir(cropRoot) for pklName in os.listdir(os.path.join(cropRoot, fileName))]\n",
    "    \n",
    "    for i, zFilePath in enumerate(cropFileList):           \n",
    "        with open(zFilePath, 'rb') as f:\n",
    "            xarDicData = pickle.load(f)\n",
    "#             print (\"0---\")\n",
    "            \n",
    "        for xar in xarDicData.values():\n",
    "            # C * D * h * w\n",
    "            xar_features = np.concatenate((xar.values[0:35], xar.values[55:]),0)\n",
    "            # C * D * h * w → C * D * hw             \n",
    "            xar_nN_hw = xar_features.reshape(channelNums, tsLength, hw*hw)\n",
    "#             print (\"1---\")\n",
    "            # C * D * hw  → C * Dhw  \n",
    "            xar_nN_D = xar_nN_hw.reshape(channelNums, -1)\n",
    "#             print (\"2---\")\n",
    "            z_total_features_l.append(xar_nN_D)\n",
    "\n",
    "\n",
    "    # l * C * Dhw → C * lDhw\n",
    "    z_C = np.concatenate(z_total_features_l, 1) \n",
    "    print (\"3---\")\n",
    "    # mean + std\n",
    "    np.save(meanFilePath, z_C.mean(axis = 1))\n",
    "    print (\"4---\")\n",
    "    np.save(stdFilePath, z_C.std(axis = 1))\n",
    "    print (\"5---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
